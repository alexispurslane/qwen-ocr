# ===============================================================================
# READ-ONLY REFERENCE FILE
# ===============================================================================
# This file contains the original monolithic implementation of the PDF OCR tool.
# It has been refactored into separate modules:
# - main.py: Core loop and business logic
# - processing.py: Prompt/Context creation and processing functions
# - pdf_handler.py: PDF/Image handling functions
# - ui.py: User interface functions
#
# DO NOT EDIT THIS FILE - it serves as a reference and backup.
# ===============================================================================

#!/usr/bin/env -S uv run --script
# /// script
# dependencies = [
#   "openai",
#   "Pillow",
#   "pdf2image",
#   "PyPDF2",
# ]
# ///

import os
import sys
import base64
import time
import shutil
import threading
import itertools
import math
import argparse
from io import BytesIO
from pathlib import Path
from typing import List, Tuple, Optional

import openai
from openai import APIStatusError
from PIL import Image
from pdf2image import convert_from_path
from PyPDF2 import PdfReader

from dataclasses import dataclass


SYSTEM_PROMPT = """You are an advanced Document Digitization Engine powered by Qwen3-VL. Your task is to convert a stream of document images into a single, semantically structured Markdown document.

You are processing a BATCH of pages from a larger document.
Context provided: Preceding text from the previous batch (for continuity).
Input provided: A sequence of images representing consecutive pages.

## CORE DIRECTIVES

1.  **Semantic Reconstruction (NOT just OCR):**
    -   Do not just extract text line-by-line. Reconstruct the logical structure.
    -   Use headers (#, ##, ###) to represent document hierarchy, not font size.
    -   Merge paragraphs that span across page breaks into a single flowing block.

2.  **Layout Noise Management:**
    -   **DETECT & REMOVE:** Running headers (e.g., "Chapter 4 | Economics") and running footers that appear identically on every page. These interrupt the reading flow.
    -   **KEEP:** Page numbers, but place them unobtrusively (e.g., `<!-- Page 42 -->`) or at the very bottom of the page content, separated by a horizontal rule `---`.

3.  **Complex Element Handling:**
    -   **Tables:** transcribing them into Markdown tables. If a table is too complex for Markdown, use HTML `<table>` tags. Merge cell content logically.
    -   **Formulas:** Detect mathematical notation and convert strictly to LaTeX format enclosed in `$` (inline) or `$$` (block).
    -   **Diagrams/Images:** If an image contains text (charts, diagrams), transcribe the key data/text. If it is purely visual, insert a placeholder: `![Description of image contents]`.

4.  **Flow & Continuity (CRITICAL):**
    -   The input images are continuous. If a sentence ends abruptly on Page X and continues on Page Y, merge them into one sentence. Do not insert a newline or page marker in the middle of a sentence.
    -   Use the "Preceding Context" to determine if the first sentence of this batch is a continuation of a previous thought.

5.  **Output Constraints:**
    -   Return **ONLY** the raw Markdown string.
    -   No "Here is the text:" preambles.
    -   No ```markdown code blocks.
"""

PRECEDING_CONTEXT_HEADER = "## PRECEDING CONTEXT (Read-Only, use for flow continuity):"
START_OF_DOCUMENT_PLACEHOLDER = "[Start of Document]"
NEW_IMAGES_HEADER_PREFIX = "\n\n## NEW IMAGES TO TRANSCRIBE ("
PAGE_LABEL_PREFIX = "\n\nPage "
PAGE_LABEL_SUFFIX = ":\n\n"

MODEL_NAME = "hf:Qwen/Qwen3-VL-235B-A22B-Instruct"
API_BASE_URL = "https://api.synthetic.new/v1/"

MAX_TOKENS = 64000
TEMPERATURE = 0.1

DEFAULT_BATCH_SIZE = 10
DEFAULT_START_PAGE = 1

IMAGE_TOKEN_SIZE = 28
PDF_DPI = 100
WHITE_THRESHOLD = 250

CONTEXT_WINDOW_SIZE = 32000 * 4  # Last 32000 tokens

MIN_HTTP_ERROR_CODE = 400
MAX_RETRY_ATTEMPTS = 3

OUTPUT_SUFFIX = "_ocr.md"
IMAGES_DIR_SUFFIX = "_images"
PAGE_IMAGE_PATTERN = "page_{:04d}.png"

DOCUMENT_BREADCRUMB_HEADER = "### DOCUMENT LOCATION BREADCRUMB\n"
CONVERTED_CONTENT_HEADER = "### CONVERTED CONTENT SO FAR\n\n"

EXPONENTIAL_BACKOFF_BASE = 2


@dataclass
class PageImage:
    page_num: int
    image_bytes: bytes
    dimensions: Tuple[int, int]  # (width, height)


def clear_screen():
    print("\033[2J\033[H", end="")


def move_cursor(row: int, col: int = 0):
    print(f"\033[{row};{col}H", end="")


def print_color(text: str, color: str = "white", bold: bool = False):
    colors = {
        "red": "\033[91m",
        "green": "\033[92m",
        "yellow": "\033[93m",
        "blue": "\033[94m",
        "magenta": "\033[95m",
        "cyan": "\033[96m",
        "white": "\033[97m",
        "gray": "\033[90m",
    }
    reset = "\033[0m"
    style = "\033[1m" if bold else ""
    print(f"{style}{colors.get(color, colors['white'])}{text}{reset}", end="")


def format_size(size_bytes: int) -> str:
    size = float(size_bytes)
    for unit in ["B", "KB", "MB", "GB"]:
        if size < 1024:
            return f"{size:.1f} {unit}"
        size /= 1024
    return f"{size:.1f} TB"


def spinner_task(stop_event, status_text="Processing..."):
    animation = itertools.cycle(["‚†ã", "‚†ô", "‚†π", "‚†∏", "‚†º", "‚†¥", "‚†¶", "‚†ß", "‚†á", "‚†è"])
    while not stop_event.is_set():
        print_color(f"\r{next(animation)} {status_text}", color="cyan", bold=True)
        sys.stdout.flush()
        time.sleep(0.1)
    print_color("\r‚úì", color="green", bold=True)
    print(" " * (len(status_text) + 2))


class SpinnerContext:
    def __init__(self, status_text="Processing..."):
        self.status_text = status_text
        self.stop_event = None
        self.spinner = None

    def __enter__(self):
        self.stop_event = threading.Event()
        self.spinner = threading.Thread(
            target=spinner_task, args=(self.stop_event, self.status_text)
        )
        self.spinner.start()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.stop_event:
            self.stop_event.set()
        if self.spinner:
            self.spinner.join()
        return False  # Don't suppress exceptions


def count_pages(pdf_path: str) -> int:
    """Quick count of pages using PDF metadata"""
    try:
        pdf = PdfReader(pdf_path)
        return len(pdf.pages)
    except Exception as e:
        print_color(f"‚ùå Error reading PDF metadata: {e}\n", color="red", bold=True)
        raise RuntimeError(f"Failed to read PDF metadata for {pdf_path}") from e


def optimize_page(img: Image.Image) -> Tuple[bytes, Tuple[int, int]]:
    img = img.convert("RGB")

    inverted = Image.eval(
        img, lambda x: 255 - x if x < WHITE_THRESHOLD else 0
    )  # Treat >250 as pure white
    bbox = inverted.getbbox()
    if bbox:
        img = img.crop(bbox)

    new_width = (img.width // IMAGE_TOKEN_SIZE) * IMAGE_TOKEN_SIZE
    new_height = (img.height // IMAGE_TOKEN_SIZE) * IMAGE_TOKEN_SIZE
    if new_width > 0 and new_height > 0:
        img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)

    buffer = BytesIO()
    img.save(buffer, format="PNG", optimize=True)
    buffer.seek(0)

    return buffer.read(), (img.width, img.height)


def pages_to_images_with_ui(
    pdf_path: str, start_page: int, end_page: int, output_dir: Optional[str] = None
) -> List[PageImage]:
    with SpinnerContext(f"Converting pages {start_page}-{end_page}..."):
        pages = convert_from_path(
            pdf_path, first_page=start_page, last_page=end_page, dpi=PDF_DPI
        )
        if not pages:
            raise ValueError("No pages found in range")

        result = []
        total_tokens = 0
        for i, page_num in enumerate(range(start_page, end_page + 1)):
            img = pages[i]
            page_bytes, (width, height) = optimize_page(img)
            tokens = (width // IMAGE_TOKEN_SIZE) * (height // IMAGE_TOKEN_SIZE)
            total_tokens += tokens

            if output_dir:
                img_path = Path(output_dir) / Path(PAGE_IMAGE_PATTERN.format(page_num))
                with open(img_path, "wb") as f:
                    f.write(page_bytes)

            result.append(PageImage(page_num, page_bytes, (width, height)))

    print_color(
        f"üìÑ Pages {start_page}-{end_page}: {total_tokens} tokens\n",
        color="green",
    )

    return result


def extract_headers(markdown: str) -> List[Tuple[int, str]]:
    headers = []
    for line in markdown.split("\n"):
        stripped = line.lstrip()
        if stripped.startswith("#"):
            # Count leading # signs
            level = len(stripped) - len(stripped.lstrip("#"))
            if level > 0 and level <= 6:  # Valid markdown header level
                # Get the header text (after the # signs and any leading space)
                header_text = stripped.lstrip("#").strip()
                if header_text:  # Only add non-empty headers
                    headers.append((level, line))  # Store the original line with hashes
    return headers


def clean_markdown_output(text: str) -> str:
    """Remove markdown code block markers from model output"""
    lines = text.split("\n")

    # Remove leading ```markdown or ``` if it's the only thing on the first line
    if lines and lines[0].strip() in ["```markdown"]:
        lines = lines[1:]

    # Remove trailing ``` if it's the only thing on the last line
    if lines and lines[-1].strip() == "```":
        lines = lines[:-1]

    return "\n".join(lines)


def update_header_stack(
    stack: List[Tuple[int, str]], new_headers: List[Tuple[int, str]]
) -> None:
    for level, header_text in new_headers:
        if not stack:
            # Empty stack, just push
            stack.append((level, header_text))
        else:
            last_level, _ = stack[-1]
            if level > last_level:
                # Deeper heading, push onto stack
                stack.append((level, header_text))
            elif level == last_level:
                # Same level, replace last
                stack[-1] = (level, header_text)
            else:  # level < last_level
                # Shallower heading, pop until we find parent
                while stack and stack[-1][0] >= level:
                    stack.pop()
                stack.append((level, header_text))


def build_image_content(images: List[PageImage]) -> tuple[list[dict[str, any]], int]:
    image_content = []
    total_tokens = 0
    for page_image in images:
        page_num = page_image.page_num
        img_bytes = page_image.image_bytes
        width, height = page_image.dimensions
        try:
            tokens = (width // IMAGE_TOKEN_SIZE) * (height // IMAGE_TOKEN_SIZE)
            total_tokens += tokens
            base64_image = base64.b64encode(img_bytes).decode("utf-8")
            # Create proper content array elements
            image_content.append(
                {
                    "type": "text",
                    "text": f"{PAGE_LABEL_PREFIX}{page_num}{PAGE_LABEL_SUFFIX}",
                }
            )
            image_content.append(
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/png;base64,{base64_image}"},
                }
            )
        except Exception as e:
            print_color(
                f"\n‚ùå Error processing page {page_num}: {e}\n", color="red", bold=True
            )
            raise RuntimeError(f"Failed to process page {page_num}") from e
    return image_content, total_tokens


def build_messages(
    context: str, image_content: list[dict[str, any]], num_images: int
) -> list[dict[str, any]]:
    return [
        {
            "role": "system",
            "content": SYSTEM_PROMPT,
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": PRECEDING_CONTEXT_HEADER
                    + "\n"
                    + (context if context else START_OF_DOCUMENT_PLACEHOLDER),
                },
                {
                    "type": "text",
                    "text": NEW_IMAGES_HEADER_PREFIX + f"{num_images} pages):",
                },
                *image_content,
            ],
        },
    ]


def process_batch(
    client: openai.OpenAI,
    images: List[PageImage],
    total_pages: int,
    batch_num: int,
    context: str = "",
) -> str:
    image_content, total_tokens = build_image_content(images)

    # Start spinner once for all retries
    with SpinnerContext(f"Processing batch {batch_num + 1}") as spinner_ctx:
        import time

        last_exception = None
        for attempt in range(MAX_RETRY_ATTEMPTS):
            try:
                response = client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=build_messages(context, image_content, len(images)),
                    max_tokens=MAX_TOKENS,
                    temperature=TEMPERATURE,
                )

                tokens = response.usage.total_tokens
                print_color(
                    f"\n‚úÖ Batch {batch_num + 1} complete: {tokens} tokens\n",
                    color="green",
                )
                return clean_markdown_output(response.choices[0].message.content)
            except APIStatusError as e:
                if e.status_code < MIN_HTTP_ERROR_CODE:
                    # Not an HTTP error, fail immediately
                    raise RuntimeError(f"API error in batch {batch_num + 1}") from e

                last_exception = e

                if (
                    attempt < MAX_RETRY_ATTEMPTS - 1
                ):  # Don't wait after the last attempt
                    wait_time = (
                        EXPONENTIAL_BACKOFF_BASE**attempt
                    )  # Exponential backoff: 1, 2, 4 seconds
                    print_color(
                        f"\n‚ö†Ô∏è  Batch {batch_num + 1} failed (attempt {attempt + 1}/{MAX_RETRY_ATTEMPTS}): HTTP {e.status_code} {str(e)}\n",
                        color="yellow",
                    )
                    print_color(
                        f"‚è≥ Retrying in {wait_time} seconds...\n", color="cyan"
                    )
                    time.sleep(wait_time)
                else:
                    raise RuntimeError(
                        f"Max retries exceeded for batch {batch_num + 1}"
                    ) from last_exception
            except Exception as e:
                # Non-HTTP errors fail immediately without retry
                raise RuntimeError(f"Unexpected error in batch {batch_num + 1}") from e


def parse_arguments():
    parser = argparse.ArgumentParser(
        description="Multi-Page PDF OCR using Qwen3-VL-235B model"
    )
    parser.add_argument("pdf_file", help="Path to the PDF file to process")
    parser.add_argument(
        "--start-page",
        type=int,
        default=DEFAULT_START_PAGE,
        help="First page to process (default: 1)",
    )
    parser.add_argument(
        "--end-page", type=int, help="Last page to process (default: all pages)"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=DEFAULT_BATCH_SIZE,
        help="Number of pages to process per batch (default: 10)",
    )
    parser.add_argument(
        "--save-images",
        action="store_true",
        help="Save processed images to a folder for inspection",
    )
    return parser.parse_args()


def validate_file(pdf_path: str) -> bool:
    if not os.path.exists(pdf_path):
        print_color(f"‚ùå File not found: {pdf_path}\n", color="red", bold=True)
        return False
    return True


def display_header(pdf_path: str, start_page: int, end_page: Optional[int]):
    clear_screen()
    print_color("üåê ", color="magenta", bold=True)
    print_color("Multi-Page PDF OCR", color="cyan", bold=True)
    print_color("ü§ñ Model: ", color="blue", bold=True)
    print_color("Qwen3-VL-235B", color="white")
    print_color("\nüìã ", color="blue", bold=True)
    print_color(pdf_path, color="white")

    if end_page:
        print_color(f" üìÑ Pages {start_page}-{end_page}", color="green")
    print("")


def get_total_pages(pdf_path: str, specified_end: Optional[int]) -> int:
    if specified_end:
        return specified_end
    print_color("üìä Counting pages...", color="yellow")
    total = count_pages(pdf_path)
    print_color(f"üìÑ Total: {total} pages\n", color="green")
    return total


def setup_output_files(pdf_path: str, save_images: bool):
    output_file = Path(pdf_path).stem + OUTPUT_SUFFIX
    images_dir = None
    if save_images:
        images_dir = Path(pdf_path).stem + IMAGES_DIR_SUFFIX
        Path(images_dir).mkdir(exist_ok=True)
        print_color(f"üíæ Saving images to: {images_dir}\n", color="blue")
    return output_file, images_dir


def build_context(all_markdown: List[str], header_stack: List[Tuple[int, str]]) -> str:
    if not all_markdown:
        return ""

    parts = []

    if header_stack:
        breadcrumb = DOCUMENT_BREADCRUMB_HEADER + "\n".join(
            "  " * (level - 1) + text for level, text in header_stack
        )
        parts.append(breadcrumb)

    parts.append(
        CONVERTED_CONTENT_HEADER + all_markdown[0]
    )  # always include first page of text
    all_text = "".join(all_markdown)
    chars_to_keep = CONTEXT_WINDOW_SIZE  # Last 32000 tokens
    recent_text = (
        all_text[-chars_to_keep:] if len(all_text) > chars_to_keep else all_text
    )
    parts.append("...\n\n" + recent_text)

    return "\n\n".join(parts)


def batch_iterator(start_page: int, end_page: int, batch_size: int):
    """Yield (batch_num, page_start, page_end) for each batch"""
    batch_num = 0
    for batch_start in range(start_page - 1, end_page, batch_size):
        page_start = batch_start + 1
        page_end = min(batch_start + batch_size, end_page)
        yield batch_num, page_start, page_end
        batch_num += 1


def process_and_save_batch(
    client: openai.OpenAI,
    pdf_path: str,
    page_start: int,
    page_end: int,
    total_pages: int,
    batch_num: int,
    batch_size: int,
    total_batches: int,
    images_dir: Optional[str],
    output_file: str,
    all_markdown: List[str],
    header_stack: List[Tuple[int, str]],
) -> None:
    print_color(
        f"üì¶ Processing batch {batch_num + 1}/{total_batches} (pages {page_start}-{page_end})\n",
        color="cyan",
        bold=True,
    )

    images = pages_to_images_with_ui(pdf_path, page_start, page_end, images_dir)
    context = build_context(all_markdown, header_stack)

    markdown = process_batch(client, images, total_pages, batch_num, context)
    all_markdown.append(markdown)

    headers = extract_headers(markdown)
    update_header_stack(header_stack, headers)

    with open(output_file, "a", encoding="utf-8") as f:
        f.write(markdown)
        f.flush()

    print_color(f"üíæ Saved to {output_file}\n", color="blue")

    if batch_num < total_batches - 1:
        time.sleep(1)


def display_results(all_markdown: List[str], output_file: str):
    print("")
    print_color("=" * shutil.get_terminal_size().columns + "\n", color="gray")

    for i, markdown in enumerate(all_markdown):
        if i > 0:
            print("\n\n")
            print_color("----\n", color="gray")
        print(markdown)

    print_color("\n‚ú® Complete!\n", color="green", bold=True)
    print_color(f"üìÑ Saved to: {output_file}\n", color="blue", bold=True)


def main():
    args = parse_arguments()

    if not validate_file(args.pdf_file):
        sys.exit(1)

    display_header(args.pdf_file, args.start_page, args.end_page)

    total_pages = get_total_pages(args.pdf_file, args.end_page)

    output_file, images_dir = setup_output_files(args.pdf_file, args.save_images)

    pages_in_range = total_pages - args.start_page + 1
    total_batches = math.ceil(pages_in_range / args.batch_size)
    if total_batches > 1:
        print_color(
            f"üì¶ {total_batches} batches of ~{args.batch_size} pages\n", color="cyan"
        )

    api_key = os.environ.get("SYNTHETIC_API_KEY")
    if not api_key:
        print_color(
            "‚ùå Set SYNTHETIC_API_KEY environment variable\n", color="red", bold=True
        )
        sys.exit(1)

    client = openai.OpenAI(api_key=api_key, base_url=API_BASE_URL)

    all_markdown: List[str] = []
    header_stack: List[Tuple[int, str]] = []

    for batch_num, page_start, page_end in batch_iterator(
        args.start_page, total_pages, args.batch_size
    ):
        process_and_save_batch(
            client,
            args.pdf_file,
            page_start,
            page_end,
            total_pages,
            batch_num,
            args.batch_size,
            total_batches,
            images_dir,
            output_file,
            all_markdown,
            header_stack,
        )

    display_results(all_markdown, output_file)


if __name__ == "__main__":
    main()
